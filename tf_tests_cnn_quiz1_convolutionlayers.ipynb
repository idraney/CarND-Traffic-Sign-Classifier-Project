{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****Using Convolution Layers in TensorFlow****\n",
    "\n",
    "Let's now apply what we've learned to build real CNNs in TensorFlow. In the below exercise, you'll be asked to set up the dimensions of the Convolution filters, the weights, the biases. This is in many ways the trickiest part to using CNNs in TensorFlow. Once you have a sense of how to set up the dimensions of these attributes, applying CNNs will be far more straight forward.\n",
    "\n",
    "\n",
    "****Review****\n",
    "\n",
    "You should go over the TensorFlow documentation for 2D convolutions. Most of the documentation is straightforward, except perhaps the padding argument. The padding might differ depending on whether you pass 'VALID' or 'SAME'.\n",
    "\n",
    "Here are a few more things worth reviewing:\n",
    "\n",
    "Introduction to TensorFlow -> TensorFlow Variables.\n",
    "    How to determine the dimensions of the output based on the input size and the filter size (shown below). You'll use this to determine what the size of your filter should be.\n",
    "\n",
    "     new_height = (input_height - filter_height + 2 * P)/S + 1\n",
    "     new_width = (input_width - filter_width + 2 * P)/S + 1\n",
    "\n",
    "****Instructions****\n",
    "\n",
    "    Finish off each TODO in the conv2d function.\n",
    "    Setup the strides, padding and filter weight/bias (F_w and F_b) such that the output shape is (1, 2, 2, 3). Note that all of these except strides should be TensorFlow variables.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'add_12:0' shape=(1, 2, 2, 3) dtype=float32>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import tensorflow as tf\n",
    "# Tensorflow 1 compatibility\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import sys, os     # Used for hidden print\n",
    "\n",
    "class HiddenPrints:\n",
    "    def __enter__(self):\n",
    "        self._original_stdout = sys.stdout\n",
    "        sys.stdout = open(os.devnull, 'w')\n",
    "\n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        sys.stdout.close()\n",
    "        sys.stdout = self._original_stdout\n",
    "\n",
    "\"\"\"\n",
    "Setup the strides, padding and filter weight/bias such that\n",
    "the output shape is (1, 2, 2, 3).\n",
    "\"\"\"\n",
    "# `tf.nn.conv2d` requires the input be 4D (batch_size, height, width, depth)\n",
    "# (1, 4, 4, 1)\n",
    "x = np.array([\n",
    "    [0, 1, 0.5, 10],\n",
    "    [2, 2.5, 1, -8],\n",
    "    [4, 0, 5, 6],\n",
    "    [15, 1, 2, 3]], dtype=np.float32).reshape((1, 4, 4, 1))\n",
    "X = tf.constant(x)\n",
    "\n",
    "def conv2d(input_array):\n",
    "    # Filter (weights and bias)\n",
    "    # The shape of the filter weight is (height, width, input_depth, output_depth)\n",
    "    # The shape of the filter bias is (output_depth,)\n",
    "    # TODO: Define the filter weights `F_W` and filter bias `F_b`.\n",
    "    # NOTE: Remember to wrap them in `tf.Variable`, they are trainable parameters after all.\n",
    "    filter_size_height = 2\n",
    "    filter_size_width = 2\n",
    "    color_channels = 1\n",
    "    k_output = 3\n",
    "\n",
    "    # TODO: Set the stride for each dimension (batch_size, height, width, depth)\n",
    "    strides = [1, 2, 2, 1]\n",
    "    \n",
    "    # TODO: set the padding, either 'VALID' or 'SAME'.\n",
    "    padding = 'VALID'\n",
    "        \n",
    "    # I want to transform the input shape (1, 4, 4, 1) to (1, 2, 2, 3). I choose 'VALID' for the padding algorithm. I find it simpler to understand and it achieves the result I'm looking for.\n",
    "    ### out_height = ceil(float(in_height - filter_height + 1) / float(strides[1]))\n",
    "    ### out_width  = ceil(float(in_width - filter_width + 1) / float(strides[2]))\n",
    "    ### out_height = ceil(float(4 - 2 + 1) / float(2)) = ceil(1.5) = 2\n",
    "    ### out_width  = ceil(float(4 - 2 + 1) / float(2)) = ceil(1.5) = 2\n",
    "    \n",
    "    # Get shape of input array for input height and width\n",
    "    with HiddenPrints():\n",
    "        in_height = print(input_array.shape[1])\n",
    "    in_height = float(0 if in_height is None else in_height)\n",
    "    with HiddenPrints():\n",
    "        in_width = print(input_array.shape[2])\n",
    "    in_width = float(0 if in_width is None else in_width)\n",
    "    \n",
    "    stride_height = strides[1]\n",
    "    stride_width = strides[2]\n",
    "\n",
    "    out_height = math.ceil(float(in_height - filter_size_height + 1)) / float(stride_height)\n",
    "    out_width  = math.ceil(float(in_width - filter_size_width + 1)) / float(stride_width)\n",
    "    \n",
    "    F_W = tf.Variable(tf.truncated_normal(\n",
    "        [filter_size_height, filter_size_width, color_channels, k_output]))\n",
    "    \n",
    "    F_b = tf.Variable(tf.zeros(k_output))\n",
    "                      \n",
    "    # https://www.tensorflow.org/versions/r0.11/api_docs/python/nn.html#conv2d\n",
    "    # `tf.nn.conv2d` does not include the bias computation so we have to add it ourselves after.\n",
    "    return tf.nn.conv2d(input_array, F_W, strides, padding) + F_b\n",
    "\n",
    "output = conv2d(X)\n",
    "output\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solution\n",
    "\n",
    "Here's how I did it. NOTE: there's more than 1 way to get the correct output shape. Your answer might differ from mine.\n",
    "\n",
    "def conv2d(input):\n",
    "    # Filter (weights and bias)\n",
    "    F_W = tf.Variable(tf.truncated_normal((2, 2, 1, 3)))\n",
    "    F_b = tf.Variable(tf.zeros(3))\n",
    "    strides = [1, 2, 2, 1]\n",
    "    padding = 'VALID'\n",
    "    return tf.nn.conv2d(input, F_W, strides, padding) + F_b\n",
    "\n",
    "I want to transform the input shape (1, 4, 4, 1) to (1, 2, 2, 3). I choose 'VALID' for the padding algorithm. I find it simpler to understand and it achieves the result I'm looking for.\n",
    "\n",
    "    out_height = ceil(float(in_height - filter_height + 1) / float(strides[1]))\n",
    "    out_width  = ceil(float(in_width - filter_width + 1) / float(strides[2]))\n",
    "\n",
    "Plugging in the values:\n",
    "\n",
    "    out_height = ceil(float(4 - 2 + 1) / float(2)) = ceil(1.5) = 2\n",
    "    out_width  = ceil(float(4 - 2 + 1) / float(2)) = ceil(1.5) = 2\n",
    "\n",
    "In order to change the depth from 1 to 3, I have to set the output depth of my filter appropriately:\n",
    "\n",
    "    F_W = tf.Variable(tf.truncated_normal((2, 2, 1, 3))) # (height, width, input_depth, output_depth)\n",
    "    F_b = tf.Variable(tf.zeros(3)) # (output_depth)\n",
    "\n",
    "The input has a depth of 1, so I set that as the input_depth of the filter.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
