{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################\n",
    "### The code in this cell works only with TensorFlow 1.x\n",
    "########################################################################\n",
    "\n",
    "# import tensorflow as tf\n",
    "\n",
    "# # Create TensorFlow object called tensor\n",
    "# hello_constant = tf.constant('Hello World!')\n",
    "\n",
    "# with tf.Session() as sess:\n",
    "#     # Run the tf.constant operation in the session\n",
    "#     output = sess.run(hello_constant)\n",
    "#     print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ian/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow_core/python/compat/v2_compat.py:88: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "b'Hello World!'\n",
      "Hello World!\n"
     ]
    }
   ],
   "source": [
    "# TensorFlow 2.1 installed\n",
    "# import tensorflow as tf\n",
    "# tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "# Tensorflow 1 compatibility\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior() \n",
    "\n",
    "# Create TensorFlow object called tensor\n",
    "hello_constant = tf.constant('Hello World!')\n",
    "\n",
    "with tf.compat.v1.Session() as sess:\n",
    "    # Run the tf.constant operation in the session\n",
    "    output = sess.run(hello_constant)\n",
    "    print(output)\n",
    "\n",
    "    output_dc = output.decode()\n",
    "    print(output_dc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello World\n"
     ]
    }
   ],
   "source": [
    "# Using feed_dict\n",
    "x = tf.placeholder(tf.string)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    output = sess.run(x, feed_dict={x: 'Hello World'})\n",
    "    \n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test String\n"
     ]
    }
   ],
   "source": [
    "# Using feed_dict with multiple tensors\n",
    "x = tf.placeholder(tf.string)\n",
    "y = tf.placeholder(tf.int32)\n",
    "z = tf.placeholder(tf.float32)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    output = sess.run(x, feed_dict={x: 'Test String', y: 123, z: 45.67})\n",
    "    print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "6\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "# Math\n",
    "x = tf.add(5, 2)  # 7\n",
    "y = tf.subtract(10, 4) # 6\n",
    "z = tf.multiply(2, 5)  # 10\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    outputx = sess.run(x)\n",
    "    outputy = sess.run(y)\n",
    "    outputz = sess.run(z)\n",
    "    print(outputx)\n",
    "    print(outputy)\n",
    "    print(outputz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "# Type casting\n",
    "x = tf.subtract(tf.cast(tf.constant(2.0), tf.int32), tf.constant(1))   # 1\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    output = sess.run(x)\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "# Generate random numbers from a normal distribution.\n",
    "# Randomizing the weights helps the model from becoming stuck in the same place every time it is trained.\n",
    "# The tf.truncated_normal() function returns a tensor with random values from a normal distribution \n",
    "# whose magnitude is no more than 2 standard deviations from the mean. \n",
    "# Use the simplest solution, setting the bias to 0.\n",
    "n_features = 120\n",
    "n_labels = 5\n",
    "weights = tf.Variable(tf.truncated_normal((n_features, n_labels)))\n",
    "bias = tf.Variable(tf.zeros(n_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2  4  6]\n",
      " [ 5  7  9]\n",
      " [ 8 10 12]\n",
      " [11 13 15]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "t = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9], [10, 11, 12]])\n",
    "u = np.array([1, 2, 3])\n",
    "print(t + u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8360188  0.11314284 0.05083836]\n",
      "[0.09003057 0.24472847 0.66524096]\n"
     ]
    }
   ],
   "source": [
    "def softmax(x):\n",
    "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
    "    # TODO: Compute and return softmax(x)\n",
    "    return np.exp(x) / np.sum(np.exp(x), axis=0)\n",
    "\n",
    "logits = [3.0, 1.0, 0.2]\n",
    "print(softmax(logits))\n",
    "\n",
    "# logits is a one-dimensional array with 3 elements\n",
    "logits = [1.0, 2.0, 3.0]\n",
    "# softmax will return a one-dimensional array with 3 elements\n",
    "print(softmax(logits))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.65223986 0.23994564 0.10781453]\n"
     ]
    }
   ],
   "source": [
    "# Tensorflow Softmax function -- does not require softmax() function above\n",
    "x = tf.nn.softmax([2.0, 1.0, 0.2])\n",
    "with tf.Session() as sess:\n",
    "    output = sess.run(x)\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6590012  0.24243298 0.09856589]\n"
     ]
    }
   ],
   "source": [
    "# Solution is available in the other \"solution.ipynb\" \n",
    "# import tensorflow as tf\n",
    "\n",
    "\n",
    "def run():\n",
    "    output = None\n",
    "    logit_data = [2.0, 1.0, 0.1]\n",
    "    logits = tf.placeholder(tf.float32)\n",
    "    \n",
    "    # TODO: Calculate the softmax of the logits\n",
    "    softmax = tf.nn.softmax(logits)    \n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        pass\n",
    "        # TODO: Feed in the logit data\n",
    "        # output = sess.run(softmax,    )\n",
    "        output = sess.run(softmax, feed_dict={logits: logit_data})\n",
    "#         print(output)\n",
    "\n",
    "    return output\n",
    "\n",
    "print(run())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-12-05ccffa6bfce>:12: read_data_sets (from tensorflow.examples.tutorials.mnist.input_data) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as: tensorflow_datasets.load('mnist')\n",
      "WARNING:tensorflow:From /home/ian/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow_core/examples/tutorials/mnist/input_data.py:297: _maybe_download (from tensorflow.examples.tutorials.mnist.input_data) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "WARNING:tensorflow:From /home/ian/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow_core/examples/tutorials/mnist/input_data.py:299: _extract_images (from tensorflow.examples.tutorials.mnist.input_data) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting /tmp/tensorflow/mnist/input_data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "WARNING:tensorflow:From /home/ian/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow_core/examples/tutorials/mnist/input_data.py:304: _extract_labels (from tensorflow.examples.tutorials.mnist.input_data) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting /tmp/tensorflow/mnist/input_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/ian/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow_core/examples/tutorials/mnist/input_data.py:112: _dense_to_one_hot (from tensorflow.examples.tutorials.mnist.input_data) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting /tmp/tensorflow/mnist/input_data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting /tmp/tensorflow/mnist/input_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/ian/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow_core/examples/tutorials/mnist/input_data.py:328: _DataSet.__init__ (from tensorflow.examples.tutorials.mnist.input_data) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/_DataSet.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "# import tensorflow as tf\n",
    "# tensorflow_datasets.load('mnist')\n",
    "# tf.keras.datasets.mnist.load_data(path='mnist.npz')\n",
    "\n",
    "\n",
    "n_input = 784  # MNIST data input (img shape: 28*28)\n",
    "n_classes = 10  # MNIST total classes (0-9 digits)\n",
    "\n",
    "# Import MNIST data\n",
    "# mnist = input_data.read_data_sets('/datasets/ud730/mnist', one_hot=True)\n",
    "mnist = input_data.read_data_sets('/tmp/tensorflow/mnist/input_data', one_hot=True)\n",
    "\n",
    "\n",
    "# The features are already scaled and the data is shuffled\n",
    "train_features = mnist.train.images\n",
    "test_features = mnist.test.images\n",
    "\n",
    "train_labels = mnist.train.labels.astype(np.float32)\n",
    "test_labels = mnist.test.labels.astype(np.float32)\n",
    "\n",
    "# Weights & bias\n",
    "weights = tf.Variable(tf.random_normal([n_input, n_classes]))\n",
    "bias = tf.Variable(tf.random_normal([n_classes]))\n",
    "\n",
    "# Features and Labels\n",
    "features = tf.placeholder(tf.float32, [None, n_input])\n",
    "labels = tf.placeholder(tf.float32, [None, n_classes])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[['F11', 'F12', 'F13', 'F14'],\n",
      "   ['F21', 'F22', 'F23', 'F24'],\n",
      "   ['F31', 'F32', 'F33', 'F34']],\n",
      "  [['L11', 'L12'], ['L21', 'L22'], ['L31', 'L32']]],\n",
      " [[['F41', 'F42', 'F43', 'F44']], [['L41', 'L42']]]]\n"
     ]
    }
   ],
   "source": [
    "### Quiz 1: Minibatch ###\n",
    "\n",
    "#from tensorflow.examples.tutorials.mnist import input_data\n",
    "# import tensorflow as tf\n",
    "# import numpy as np\n",
    "\n",
    "### from helper import batches ###\n",
    "import math\n",
    "\n",
    "def batches(batch_size, features, labels):\n",
    "    \"\"\"\n",
    "    Create batches of features and labels\n",
    "    :param batch_size: The batch size\n",
    "    :param features: List of features\n",
    "    :param labels: List of labels\n",
    "    :return: Batches of (Features, Labels)\n",
    "    \"\"\"\n",
    "    assert len(features) == len(labels)\n",
    "    # TODO: Implement batching\n",
    "    output_batches = []\n",
    "    \n",
    "    sample_size = len(features)\n",
    "    for start_i in range(0, sample_size, batch_size):\n",
    "        end_i = start_i + batch_size\n",
    "        batch = [features[start_i:end_i], labels[start_i:end_i]]\n",
    "        output_batches.append(batch)\n",
    "        \n",
    "    return output_batches\n",
    "\n",
    "\n",
    "\n",
    "# from quiz import batches\n",
    "from pprint import pprint\n",
    "\n",
    "# 4 Samples of features\n",
    "example_features = [\n",
    "    ['F11','F12','F13','F14'],\n",
    "    ['F21','F22','F23','F24'],\n",
    "    ['F31','F32','F33','F34'],\n",
    "    ['F41','F42','F43','F44']]\n",
    "# 4 Samples of labels\n",
    "example_labels = [\n",
    "    ['L11','L12'],\n",
    "    ['L21','L22'],\n",
    "    ['L31','L32'],\n",
    "    ['L41','L42']]\n",
    "\n",
    "# PPrint prints data structures like 2d arrays, so they are easier to read\n",
    "pprint(batches(3, example_features, example_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/tensorflow/mnist/input_data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/tensorflow/mnist/input_data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/tensorflow/mnist/input_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/tensorflow/mnist/input_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From <ipython-input-14-fef41372a290>:37: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "Test Accuracy: 0.10199999809265137\n"
     ]
    }
   ],
   "source": [
    "### Quiz 2: Minibatch ###\n",
    "### imports already imported or defined ###\n",
    "# from tensorflow.examples.tutorials.mnist import input_data\n",
    "# import tensorflow as tf\n",
    "# import numpy as np\n",
    "# from helper import batches\n",
    "\n",
    "learning_rate = 0.001\n",
    "n_input = 784  # MNIST data input (img shape: 28*28)\n",
    "n_classes = 10  # MNIST total classes (0-9 digits)\n",
    "\n",
    "# Import MNIST data\n",
    "##### Udacity\n",
    "# mnist = input_data.read_data_sets('/datasets/ud730/mnist', one_hot=True)\n",
    "##### Local computer\n",
    "mnist = input_data.read_data_sets('/tmp/tensorflow/mnist/input_data', one_hot=True)\n",
    "\n",
    "# The features are already scaled and the data is shuffled\n",
    "train_features = mnist.train.images\n",
    "test_features = mnist.test.images\n",
    "\n",
    "train_labels = mnist.train.labels.astype(np.float32)\n",
    "test_labels = mnist.test.labels.astype(np.float32)\n",
    "\n",
    "# Features and Labels\n",
    "features = tf.placeholder(tf.float32, [None, n_input])\n",
    "labels = tf.placeholder(tf.float32, [None, n_classes])\n",
    "\n",
    "# Weights & bias\n",
    "weights = tf.Variable(tf.random_normal([n_input, n_classes]))\n",
    "bias = tf.Variable(tf.random_normal([n_classes]))\n",
    "\n",
    "# Logits - xW + b\n",
    "logits = tf.add(tf.matmul(features, weights), bias)\n",
    "\n",
    "# Define loss and optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=labels))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "# Calculate accuracy\n",
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(labels, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "################\n",
    "\n",
    "# TODO: Set batch size\n",
    "batch_size = 128\n",
    "assert batch_size is not None, 'You must set the batch size'\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    # TODO: Train optimizer on all batches\n",
    "    for batch_features, batch_labels in batches(batch_size, train_features, train_labels):\n",
    "        sess.run(optimizer, feed_dict={features: batch_features, labels: batch_labels})\n",
    "\n",
    "    # Calculate accuracy for test dataset\n",
    "    test_accuracy = sess.run(\n",
    "        accuracy,feed_dict={features: test_features, labels: test_labels})\n",
    "\n",
    "print('Test Accuracy: {}'.format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# print (tf .__file__)\n",
    "# from tensorflow.examples.tutorials.mnist import input_data\n",
    "# print(input_data.__file__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Epochs\n",
    "\n",
    "An epoch is a single forward and backward pass of the whole dataset. This is used to increase the accuracy of the model without requiring more data. This section will cover epochs in TensorFlow and how to choose the right number of epochs.\n",
    "\n",
    "The following TensorFlow code trains a model using 10 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/tensorflow/mnist/input_data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/tensorflow/mnist/input_data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/tensorflow/mnist/input_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/tensorflow/mnist/input_data/t10k-labels-idx1-ubyte.gz\n",
      "Epoch: 0    - Cost: 12.6     Valid Accuracy: 0.0902\n",
      "Epoch: 1    - Cost: 10.6     Valid Accuracy: 0.097\n",
      "Epoch: 2    - Cost: 9.37     Valid Accuracy: 0.108\n",
      "Epoch: 3    - Cost: 8.57     Valid Accuracy: 0.124\n",
      "Epoch: 4    - Cost: 8.02     Valid Accuracy: 0.145\n",
      "Epoch: 5    - Cost: 7.63     Valid Accuracy: 0.162\n",
      "Epoch: 6    - Cost: 7.32     Valid Accuracy: 0.18 \n",
      "Epoch: 7    - Cost: 7.06     Valid Accuracy: 0.2  \n",
      "Epoch: 8    - Cost: 6.83     Valid Accuracy: 0.221\n",
      "Epoch: 9    - Cost: 6.61     Valid Accuracy: 0.239\n",
      "Epoch: 10   - Cost: 6.4      Valid Accuracy: 0.257\n",
      "Epoch: 11   - Cost: 6.21     Valid Accuracy: 0.276\n",
      "Epoch: 12   - Cost: 6.03     Valid Accuracy: 0.292\n",
      "Epoch: 13   - Cost: 5.86     Valid Accuracy: 0.308\n",
      "Epoch: 14   - Cost: 5.69     Valid Accuracy: 0.325\n",
      "Epoch: 15   - Cost: 5.54     Valid Accuracy: 0.342\n",
      "Epoch: 16   - Cost: 5.4      Valid Accuracy: 0.356\n",
      "Epoch: 17   - Cost: 5.27     Valid Accuracy: 0.37 \n",
      "Epoch: 18   - Cost: 5.14     Valid Accuracy: 0.386\n",
      "Epoch: 19   - Cost: 5.02     Valid Accuracy: 0.399\n",
      "Epoch: 20   - Cost: 4.91     Valid Accuracy: 0.411\n",
      "Epoch: 21   - Cost: 4.8      Valid Accuracy: 0.425\n",
      "Epoch: 22   - Cost: 4.7      Valid Accuracy: 0.435\n",
      "Epoch: 23   - Cost: 4.6      Valid Accuracy: 0.446\n",
      "Epoch: 24   - Cost: 4.51     Valid Accuracy: 0.46 \n",
      "Epoch: 25   - Cost: 4.43     Valid Accuracy: 0.472\n",
      "Epoch: 26   - Cost: 4.34     Valid Accuracy: 0.482\n",
      "Epoch: 27   - Cost: 4.26     Valid Accuracy: 0.491\n",
      "Epoch: 28   - Cost: 4.19     Valid Accuracy: 0.501\n",
      "Epoch: 29   - Cost: 4.11     Valid Accuracy: 0.508\n",
      "Epoch: 30   - Cost: 4.04     Valid Accuracy: 0.517\n",
      "Epoch: 31   - Cost: 3.98     Valid Accuracy: 0.523\n",
      "Epoch: 32   - Cost: 3.91     Valid Accuracy: 0.531\n",
      "Epoch: 33   - Cost: 3.85     Valid Accuracy: 0.536\n",
      "Epoch: 34   - Cost: 3.8      Valid Accuracy: 0.541\n",
      "Epoch: 35   - Cost: 3.74     Valid Accuracy: 0.546\n",
      "Epoch: 36   - Cost: 3.69     Valid Accuracy: 0.553\n",
      "Epoch: 37   - Cost: 3.63     Valid Accuracy: 0.559\n",
      "Epoch: 38   - Cost: 3.58     Valid Accuracy: 0.564\n",
      "Epoch: 39   - Cost: 3.54     Valid Accuracy: 0.568\n",
      "Epoch: 40   - Cost: 3.49     Valid Accuracy: 0.572\n",
      "Epoch: 41   - Cost: 3.45     Valid Accuracy: 0.577\n",
      "Epoch: 42   - Cost: 3.4      Valid Accuracy: 0.583\n",
      "Epoch: 43   - Cost: 3.36     Valid Accuracy: 0.586\n",
      "Epoch: 44   - Cost: 3.32     Valid Accuracy: 0.591\n",
      "Epoch: 45   - Cost: 3.28     Valid Accuracy: 0.595\n",
      "Epoch: 46   - Cost: 3.24     Valid Accuracy: 0.6  \n",
      "Epoch: 47   - Cost: 3.2      Valid Accuracy: 0.604\n",
      "Epoch: 48   - Cost: 3.17     Valid Accuracy: 0.608\n",
      "Epoch: 49   - Cost: 3.13     Valid Accuracy: 0.613\n",
      "Epoch: 50   - Cost: 3.1      Valid Accuracy: 0.616\n",
      "Epoch: 51   - Cost: 3.06     Valid Accuracy: 0.62 \n",
      "Epoch: 52   - Cost: 3.03     Valid Accuracy: 0.624\n",
      "Epoch: 53   - Cost: 3.0      Valid Accuracy: 0.629\n",
      "Epoch: 54   - Cost: 2.97     Valid Accuracy: 0.631\n",
      "Epoch: 55   - Cost: 2.94     Valid Accuracy: 0.634\n",
      "Epoch: 56   - Cost: 2.91     Valid Accuracy: 0.636\n",
      "Epoch: 57   - Cost: 2.88     Valid Accuracy: 0.639\n",
      "Epoch: 58   - Cost: 2.85     Valid Accuracy: 0.642\n",
      "Epoch: 59   - Cost: 2.82     Valid Accuracy: 0.645\n",
      "Epoch: 60   - Cost: 2.79     Valid Accuracy: 0.648\n",
      "Epoch: 61   - Cost: 2.77     Valid Accuracy: 0.65 \n",
      "Epoch: 62   - Cost: 2.74     Valid Accuracy: 0.653\n",
      "Epoch: 63   - Cost: 2.71     Valid Accuracy: 0.656\n",
      "Epoch: 64   - Cost: 2.69     Valid Accuracy: 0.658\n",
      "Epoch: 65   - Cost: 2.66     Valid Accuracy: 0.662\n",
      "Epoch: 66   - Cost: 2.64     Valid Accuracy: 0.664\n",
      "Epoch: 67   - Cost: 2.61     Valid Accuracy: 0.666\n",
      "Epoch: 68   - Cost: 2.59     Valid Accuracy: 0.669\n",
      "Epoch: 69   - Cost: 2.57     Valid Accuracy: 0.67 \n",
      "Epoch: 70   - Cost: 2.54     Valid Accuracy: 0.673\n",
      "Epoch: 71   - Cost: 2.52     Valid Accuracy: 0.677\n",
      "Epoch: 72   - Cost: 2.5      Valid Accuracy: 0.679\n",
      "Epoch: 73   - Cost: 2.48     Valid Accuracy: 0.681\n",
      "Epoch: 74   - Cost: 2.46     Valid Accuracy: 0.683\n",
      "Epoch: 75   - Cost: 2.44     Valid Accuracy: 0.684\n",
      "Epoch: 76   - Cost: 2.42     Valid Accuracy: 0.687\n",
      "Epoch: 77   - Cost: 2.4      Valid Accuracy: 0.689\n",
      "Epoch: 78   - Cost: 2.38     Valid Accuracy: 0.691\n",
      "Epoch: 79   - Cost: 2.36     Valid Accuracy: 0.693\n",
      "Epoch: 80   - Cost: 2.34     Valid Accuracy: 0.695\n",
      "Epoch: 81   - Cost: 2.32     Valid Accuracy: 0.696\n",
      "Epoch: 82   - Cost: 2.3      Valid Accuracy: 0.698\n",
      "Epoch: 83   - Cost: 2.28     Valid Accuracy: 0.7  \n",
      "Epoch: 84   - Cost: 2.27     Valid Accuracy: 0.702\n",
      "Epoch: 85   - Cost: 2.25     Valid Accuracy: 0.703\n",
      "Epoch: 86   - Cost: 2.23     Valid Accuracy: 0.706\n",
      "Epoch: 87   - Cost: 2.22     Valid Accuracy: 0.707\n",
      "Epoch: 88   - Cost: 2.2      Valid Accuracy: 0.708\n",
      "Epoch: 89   - Cost: 2.18     Valid Accuracy: 0.709\n",
      "Epoch: 90   - Cost: 2.17     Valid Accuracy: 0.709\n",
      "Epoch: 91   - Cost: 2.15     Valid Accuracy: 0.712\n",
      "Epoch: 92   - Cost: 2.14     Valid Accuracy: 0.713\n",
      "Epoch: 93   - Cost: 2.12     Valid Accuracy: 0.715\n",
      "Epoch: 94   - Cost: 2.11     Valid Accuracy: 0.716\n",
      "Epoch: 95   - Cost: 2.09     Valid Accuracy: 0.718\n",
      "Epoch: 96   - Cost: 2.08     Valid Accuracy: 0.719\n",
      "Epoch: 97   - Cost: 2.06     Valid Accuracy: 0.72 \n",
      "Epoch: 98   - Cost: 2.05     Valid Accuracy: 0.72 \n",
      "Epoch: 99   - Cost: 2.03     Valid Accuracy: 0.721\n",
      "Test Accuracy: 0.7264000177383423\n"
     ]
    }
   ],
   "source": [
    "# from tensorflow.examples.tutorials.mnist import input_data\n",
    "# import tensorflow as tf\n",
    "# import numpy as np\n",
    "# from helper import batches  # Helper function created in Mini-batching section\n",
    "\n",
    "\n",
    "def print_epoch_stats(epoch_i, sess, last_features, last_labels):\n",
    "    \"\"\"\n",
    "    Print cost and validation accuracy of an epoch\n",
    "    \"\"\"\n",
    "    current_cost = sess.run(\n",
    "        cost,\n",
    "        feed_dict={features: last_features, labels: last_labels})\n",
    "    valid_accuracy = sess.run(\n",
    "        accuracy,\n",
    "        feed_dict={features: valid_features, labels: valid_labels})\n",
    "    print('Epoch: {:<4} - Cost: {:<8.3} Valid Accuracy: {:<5.3}'.format(\n",
    "        epoch_i,\n",
    "        current_cost,\n",
    "        valid_accuracy))\n",
    "\n",
    "n_input = 784  # MNIST data input (img shape: 28*28)\n",
    "n_classes = 10  # MNIST total classes (0-9 digits)\n",
    "\n",
    "# Import MNIST data\n",
    "##### Udacity\n",
    "# mnist = input_data.read_data_sets('/datasets/ud730/mnist', one_hot=True)\n",
    "##### Local computer\n",
    "mnist = input_data.read_data_sets('/tmp/tensorflow/mnist/input_data', one_hot=True)\n",
    "\n",
    "# The features are already scaled and the data is shuffled\n",
    "train_features = mnist.train.images\n",
    "valid_features = mnist.validation.images\n",
    "test_features = mnist.test.images\n",
    "\n",
    "train_labels = mnist.train.labels.astype(np.float32)\n",
    "valid_labels = mnist.validation.labels.astype(np.float32)\n",
    "test_labels = mnist.test.labels.astype(np.float32)\n",
    "\n",
    "# Features and Labels\n",
    "features = tf.placeholder(tf.float32, [None, n_input])\n",
    "labels = tf.placeholder(tf.float32, [None, n_classes])\n",
    "\n",
    "# Weights & bias\n",
    "weights = tf.Variable(tf.random_normal([n_input, n_classes]))\n",
    "bias = tf.Variable(tf.random_normal([n_classes]))\n",
    "\n",
    "# Logits - xW + b\n",
    "logits = tf.add(tf.matmul(features, weights), bias)\n",
    "\n",
    "# Define loss and optimizer\n",
    "learning_rate = tf.placeholder(tf.float32)\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=labels))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "# Calculate accuracy\n",
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(labels, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "batch_size = 128\n",
    "epochs = 100\n",
    "learn_rate = 0.001\n",
    "\n",
    "train_batches = batches(batch_size, train_features, train_labels)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    # Training cycle\n",
    "    for epoch_i in range(epochs):\n",
    "\n",
    "        # Loop over all batches\n",
    "        for batch_features, batch_labels in train_batches:\n",
    "            train_feed_dict = {\n",
    "                features: batch_features,\n",
    "                labels: batch_labels,\n",
    "                learning_rate: learn_rate}\n",
    "            sess.run(optimizer, feed_dict=train_feed_dict)\n",
    "\n",
    "        # Print cost and validation accuracy of an epoch\n",
    "        print_epoch_stats(epoch_i, sess, batch_features, batch_labels)\n",
    "\n",
    "    # Calculate accuracy for test dataset\n",
    "    test_accuracy = sess.run(\n",
    "        accuracy,\n",
    "        feed_dict={features: test_features, labels: test_labels})\n",
    "\n",
    "print('Test Accuracy: {}'.format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow lab at ~/workspace/udacity/CarND-TensorFlow-Lab/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
